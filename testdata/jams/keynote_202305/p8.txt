大模型的涌现，推动着GPU云计算的未来，对GPU算力平台的要求也越来越高。
下面，我们进入发布会的第6部分，算力平台。
大模型促进了当下正在发生的算力革命，多机多卡的GPU算力集群，成为了必然趋势。
让开发者，云服务提供商，以及数据中心，以更低的成本、更便捷的部署、管理、调度、和运营大规模GPU集群，更好的开发应用，是GPU云计算的整体目标，也是摩尔线程重点发展的方向。
今天，我们发布，摩尔线程自研的高性能GPU算力集群产品：MMCPlatform。
MMCPlatform可以支持不同品牌的GPU计算卡的混合调度和计算，能够同时支持容器和虚拟机的运行时管理，提供高性能的网络、高性能的分布式存储管理能力等。
解决了集群计算场景的算力调度、资源管理和监控的问题，同时可以保障大规模GPU计算的可靠性，更好地为AI大模型训练、元宇宙、物理仿真、高性能计算等提供服务。 
同时，我们会在MMCPlatform之上，提供一整套应用开发工程化平台，MMCFlow。
你们都知道，人工智能三要素是算力、算法和数据，
而对于实现人工智能的商业应用和持续发展的重要因素，就是“工程化能力”。
MMCFlow为AI 模型的开发，提供了完整的数据集管理、代码开发、模型训练、推理部署、运行监控等方案，
集成了摩尔线程最新的生态工具集，包括AI框架、模型、算子及加速库，让开发者和生态伙伴可以基于摩尔线程的算力，低成本地、从0开发应用并运行起来。
平台支持最新的大模型分布式训练和推理，支持断点续训和弹性伸缩，并在后续版本支持代码生成开发和测试，大幅提升应用开发的效率。
MMCFlow，充分赋能各行业开发智能化业务，让算力、平台和应用完美结合，开箱即用。
目前，基于摩尔线程的MMCPlatform与MMCFlow平台，利用MT Pytorch框架和MUSA，我们已经完成了ChatGLM，LLaMA，以及摩尔线程自研的MUSAChat，MUSABert等模型的训练和推理应用。